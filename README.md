
# Sales Analytics Project â€” PySpark on Databricks
## Overview

- This project demonstrates a Sales Analytics Pipeline built using PySpark on Databricks Community Edition.
It covers key data engineering skills including:

- Reading CSV files with explicit schema

- Data cleaning and transformation

- Joining multiple datasets

- Aggregating business metrics

- Using Databricks notebooks for interactive analysis

- This is a student-ready, real-world style analytics project.

# Dataset Description

This analysis uses two CSV datasets:

- menu.csv â€“ Contains item details such as product name and category

- sales.csv â€“ Contains transaction records for sales

Note: CSV files are not stored in the repository. You can upload them in Databricks using the â€œCreate and modify tableâ€ option.

# Key Features

This project showcases:

- Explicit schema definition for CSV files

- Handling CSV files with no header row

- Schema-based ingestion using StructType and StructField

- PySpark DataFrame transformations and functions

- Joins between sales and menu datasets

- Business aggregations like total sales by category

- Use of Databricks notebooks and visualizations

# Business Insights

This analysis enables answering key business questions such as:

ğŸ“Œ Total sales revenue by product

ğŸ“Œ Monthly sales trends

ğŸ“Œ Category-wise sales performance

ğŸ“Œ Customer purchase behavior

# Link
- Visualization
https://dbc-0ac5dfe1-c9fd.cloud.databricks.com/editor/notebooks/3053131247986319/dashboards/997129b0-a4e4-4a08-8e03-589f1cf6f7eb?o=7474648638191100
